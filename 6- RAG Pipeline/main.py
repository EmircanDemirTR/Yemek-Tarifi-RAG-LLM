"""
RAG Pipeline - Ä°nteraktif ArayÃ¼z
"""
import os
import sys

# Windows terminal encoding
if sys.platform == 'win32':
    os.system('chcp 65001 >nul 2>&1')
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')

from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.prompt import Prompt
from rich.markdown import Markdown

from rag_pipeline import RAGPipeline
from llm_local import get_available_models

console = Console()


def print_welcome():
    """HoÅŸ geldin mesajÄ±"""
    console.print(Panel.fit(
        "[bold cyan]ğŸ³ RAG Tarif AsistanÄ±[/bold cyan]\n"
        "[dim]Retrieval-Augmented Generation ile TÃ¼rk MutfaÄŸÄ±[/dim]",
        border_style="cyan"
    ))


def print_help():
    """YardÄ±m mesajÄ±"""
    help_text = """
[bold]Komutlar:[/bold]
  [cyan]/rag[/cyan] <soru>      RAG modu (veritabanÄ±ndan context ile)
  [cyan]/llm[/cyan] <soru>      LLM-Only modu (sadece model bilgisi)
  [cyan]/karsilastir[/cyan]     AynÄ± soruyu her iki modda test et
  [cyan]/model[/cyan] <isim>    Ollama modelini deÄŸiÅŸtir
  [cyan]/groq[/cyan]            Groq API'ye geÃ§
  [cyan]/modeller[/cyan]        Mevcut modelleri gÃ¶ster
  [cyan]/yardim[/cyan]          Bu menÃ¼yÃ¼ gÃ¶ster
  [cyan]/cikis[/cyan]           Ã‡Ä±kÄ±ÅŸ

[bold]Ã–rnekler:[/bold]
  /rag Mercimek Ã§orbasÄ± nasÄ±l yapÄ±lÄ±r?
  /llm Baklava tarifi ver
  /karsilastir KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r?
"""
    console.print(Panel(help_text, title="YardÄ±m", border_style="green"))


def show_models():
    """Mevcut modelleri gÃ¶ster"""
    table = Table(title="Mevcut LLM Modelleri")
    table.add_column("Model", style="cyan")
    table.add_column("Boyut", style="green")
    table.add_column("HÄ±z", style="yellow")
    table.add_column("Durum", style="magenta")
    
    # Groq
    table.add_row("groq (Llama 3.3 70B)", "70B", "ğŸš€ Ã‡ok HÄ±zlÄ±", "âœ“ API")
    
    # Ollama
    available = get_available_models()
    for model_id, info in available.items():
        status = "âœ“ YÃ¼klÃ¼" if info.get("installed") else "âœ— YÃ¼klenmemiÅŸ"
        table.add_row(model_id, info["size"], info["speed"], status)
    
    console.print(table)


def display_result(result: dict):
    """Sonucu gÃ¶ster"""
    mode = result.get("mode", "unknown")
    mode_text = "ğŸ” RAG" if mode == "rag" else "ğŸ¤– LLM-Only"
    
    # Cevap paneli
    console.print(Panel(
        result["answer"],
        title=f"{mode_text} Cevap",
        border_style="green"
    ))
    
    # Metrikler
    llm_result = result.get("llm_result", {})
    latency = llm_result.get("latency_ms", 0)
    tokens = llm_result.get("tokens", 0)
    model = llm_result.get("model", "unknown")
    provider = llm_result.get("provider", "unknown")
    
    console.print(f"[dim]Model: {provider}/{model} | Latency: {latency:.0f}ms | Tokens: {tokens}[/dim]")
    
    # RAG modunda bulunan tarifler
    if mode == "rag" and "retrieved_recipes" in result:
        recipes = result["retrieved_recipes"]
        if recipes:
            console.print(f"\n[dim]ğŸ“š Bulunan {len(recipes)} tarif:[/dim]")
            for i, r in enumerate(recipes[:3], 1):
                title = r.get("title", "Bilinmiyor")
                score = r.get("score", 0)
                console.print(f"[dim]   {i}. {title} (skor: {score:.2f})[/dim]")


def compare_modes(rag: RAGPipeline, question: str):
    """RAG ve LLM-Only modlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±r"""
    console.print(f"\n[bold]Soru:[/bold] {question}\n")
    
    # LLM-Only
    console.print("[bold yellow]1. LLM-Only Modu[/bold yellow]")
    llm_result = rag.query_llm_only(question)
    display_result(llm_result)
    
    # RAG
    console.print("\n[bold cyan]2. RAG Modu[/bold cyan]")
    rag_result = rag.query_rag(question)
    display_result(rag_result)
    
    # KarÅŸÄ±laÅŸtÄ±rma Ã¶zeti
    console.print("\n[bold]ğŸ“Š KarÅŸÄ±laÅŸtÄ±rma:[/bold]")
    table = Table()
    table.add_column("Metrik", style="cyan")
    table.add_column("LLM-Only", style="yellow")
    table.add_column("RAG", style="green")
    
    table.add_row(
        "Latency",
        f"{llm_result['llm_result']['latency_ms']:.0f}ms",
        f"{rag_result['llm_result']['latency_ms']:.0f}ms"
    )
    table.add_row(
        "Tokens",
        str(llm_result['llm_result'].get('tokens', 0)),
        str(rag_result['llm_result'].get('tokens', 0))
    )
    table.add_row(
        "Context",
        "Yok",
        f"{len(rag_result.get('retrieved_recipes', []))} tarif"
    )
    
    console.print(table)


def main():
    """Ana fonksiyon"""
    print_welcome()
    
    # VarsayÄ±lan olarak Groq ile baÅŸla
    try:
        rag = RAGPipeline(llm_provider="groq")
        console.print("[green]âœ“ Groq API hazÄ±r[/green]")
    except ValueError:
        console.print("[yellow]âš  Groq API key bulunamadÄ±, Ollama ile baÅŸlanÄ±yor[/yellow]")
        rag = RAGPipeline(llm_provider="ollama")
    
    print_help()
    
    while True:
        try:
            user_input = Prompt.ask("\n[bold cyan]>[/bold cyan]").strip()
            
            if not user_input:
                continue
            
            # KomutlarÄ± iÅŸle
            if user_input.lower() in ["/cikis", "/exit", "/q"]:
                console.print("[yellow]GÃ¶rÃ¼ÅŸmek Ã¼zere! ğŸ‘‹[/yellow]")
                break
            
            elif user_input.lower() in ["/yardim", "/help", "/h"]:
                print_help()
            
            elif user_input.lower() in ["/modeller", "/models"]:
                show_models()
            
            elif user_input.lower() == "/groq":
                try:
                    rag.switch_llm("groq")
                    console.print("[green]âœ“ Groq API'ye geÃ§ildi[/green]")
                except ValueError as e:
                    console.print(f"[red]âœ— {e}[/red]")
            
            elif user_input.lower().startswith("/model "):
                model_name = user_input[7:].strip()
                rag.switch_llm("ollama", model_name)
                console.print(f"[green]âœ“ Model deÄŸiÅŸtirildi: {model_name}[/green]")
            
            elif user_input.lower().startswith("/karsilastir"):
                parts = user_input.split(maxsplit=1)
                if len(parts) > 1:
                    question = parts[1]
                else:
                    question = Prompt.ask("Soru")
                compare_modes(rag, question)
            
            elif user_input.lower().startswith("/rag "):
                question = user_input[5:].strip()
                if question:
                    with console.status("[bold green]RAG sorgulanÄ±yor..."):
                        result = rag.query_rag(question)
                    display_result(result)
            
            elif user_input.lower().startswith("/llm "):
                question = user_input[5:].strip()
                if question:
                    with console.status("[bold yellow]LLM sorgulanÄ±yor..."):
                        result = rag.query_llm_only(question)
                    display_result(result)
            
            else:
                # VarsayÄ±lan: RAG modu
                with console.status("[bold green]RAG sorgulanÄ±yor..."):
                    result = rag.query_rag(user_input)
                display_result(result)
        
        except KeyboardInterrupt:
            console.print("\n[yellow]Ä°ptal edildi[/yellow]")
            continue
        except Exception as e:
            console.print(f"[red]Hata: {e}[/red]")


if __name__ == "__main__":
    main()

